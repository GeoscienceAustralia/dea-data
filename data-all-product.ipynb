{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import os.path\n",
    "from statistics import mean \n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import gpdvega\n",
    "import json\n",
    "import datetime\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_hex\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "import re\n",
    "\n",
    "colormap = cm.spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    with open(filename, newline='') as File:  \n",
    "        reader = csv.reader(File)\n",
    "        header1 = next(reader)\n",
    "        header2 = next(reader)\n",
    "        results = []\n",
    "        for row in reader:\n",
    "            folder = Path(row[0].strip(\"'\"))\n",
    "            parts = folder.parts\n",
    "            if len(parts) > 2 and parts[-1].lower().endswith('.tif'):\n",
    "                results.append({\"folder\": str(folder.parent), \"hits\": int(row[1]), \"bytes\": int(row[2]), \"cost\": float(row[3])})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    with open(filename, encoding='utf-8') as File:  \n",
    "        reader = json.loads(File.read())\n",
    "        reader_files = reader['Files']\n",
    "        today = datetime.date.today()  \n",
    "        results = []\n",
    "        for i,v in reader_files.items():\n",
    "            if str(i).endswith('.TIF') or str(i).endswith('.tif') or str(i).endswith('.tiff'):\n",
    "                results.append({\"folder\": str(i), \"hits\": int(v[0]), \"bytes\": int(v[1]), 'date':today})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_namee=\"201909.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date = file_namee.split(\".\")[0][:4]+ \"-\" + file_namee.split(\".\")[0][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date+ '-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entries = read_json(file_namee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_index_from_path(path):\n",
    "    def go(part):\n",
    "        pattern = r'(?P<key>[xy])_(?P<num>.*)'\n",
    "        match = re.match(pattern, part, re.IGNORECASE)\n",
    "        if match is None:\n",
    "            return {}\n",
    "        gd = match.groupdict()\n",
    "        return {gd['key']: gd['num']}\n",
    "    \n",
    "    result = {}\n",
    "    for part in path.split('/'):\n",
    "        result.update(go(part))\n",
    "    return ((result['x']), (result['y']))\n",
    "\n",
    "\n",
    "def product_name(folder):\n",
    "    parts = Path(folder).parts\n",
    "    if parts[0] == 'mangrove_cover':\n",
    "        return parts[0]\n",
    "    return os.path.join(*parts[:2])\n",
    "\n",
    "\n",
    "def spatial_id(folder):\n",
    "    parts = Path(folder).parts\n",
    "    print(parts)\n",
    "    print(parts[-1])\n",
    "    if parts[-2] in ['NBAR', 'NBART', 'QA', 'SUPPLEMENTARY', 'LAMBERTIAN']:\n",
    "        print(\"OK\")\n",
    "    if len(parts) > 2 and parts[0] == 'L2' and parts[1] == 'sentinel-2-nrt' and parts[-2] in ['NBAR', 'NBART', 'QA', 'SUPPLEMENTARY', 'LAMBERTIAN']:\n",
    "        try:\n",
    "            print(parts[-3].split(\"_\")[-2][1:])\n",
    "            return parts[-3].split(\"_\")[-2][1:]\n",
    "        except IndexError:\n",
    "            print(folder)\n",
    "    if len(parts) >2 and parts[0] == 'hltc' or parts[0] == 'item_v2':\n",
    "        try:\n",
    "            print(parts[-1].split(\"_\")[2])\n",
    "            return parts[-1].split(\"_\")[2]\n",
    "        except IndexError:\n",
    "            print(folder)\n",
    "    if len(parts) >2 and parts[0] == 'nidem':\n",
    "        try:\n",
    "            print(parts[-1].split(\"_\")[1])\n",
    "            return parts[-1].split(\"_\")[1]\n",
    "        except IndexError:\n",
    "            print(folder)\n",
    "    elif len(parts) >2 and parts[0]=='bare-earth' or parts[0]=='geomedian-australia' or parts[0]=='WOfS' or parts[0]=='fractional-cover':\n",
    "        return ','.join(tile_index_from_path(folder))\n",
    "    elif len(parts) >2 and parts[0] == 'projects' or parts[0] == 'weathering-intensity':\n",
    "        return ' '\n",
    "    elif len(parts) >2 and parts[0] == 'multi-scale-topographic-position':\n",
    "        return ' '\n",
    "    else:\n",
    "        return '<none>'\n",
    "\n",
    "\n",
    "def coordsgeojson(spatialid):\n",
    "    with open('australian-mgrs-tiles.geojson') as fl:\n",
    "        input_gj = json.load(fl)\n",
    "    feats = input_gj['features']\n",
    "    for feat in feats:\n",
    "        if 'MGRS' in feat['properties']:\n",
    "            mgrs = feat['properties']['MGRS']\n",
    "            if spatial_id == mgrs:\n",
    "                polygon = Polygon(feat[\"geometry\"]['coordinates'][0])\n",
    "                lat = round(polygon.centroid.y, 1)\n",
    "                lon = round(polygon.centroid.x, 1) \n",
    "                return lat\n",
    "    \n",
    "    \n",
    "    \n",
    "def latcord(folder, spatialid):\n",
    "    parts = Path(folder).parts\n",
    "\n",
    "    if len(parts) >2 and parts[0] == 'hltc' or parts[0] == 'item_v2':\n",
    "\n",
    "        return (parts[-1].split('.tif'))[0].split(\"_\")[4]\n",
    "    elif len(parts) >2 and parts[0] == 'nidem':\n",
    "        return parts[-1].split(\"_\")[3]\n",
    "    elif len(parts) >2 and parts[0] == 'projects' or parts[0] == 'weathering-intensity':\n",
    "        return ' '\n",
    "    elif len(parts) >2 and parts[0] == 'multi-scale-topographic-position':\n",
    "        return ' '\n",
    "    else:\n",
    "        return '<none>'\n",
    "\n",
    "    \n",
    "def loncord(folder, spatialid):\n",
    "    parts = Path(folder).parts\n",
    "    if len(parts) >2 and parts[0] == 'hltc' or parts[0] == 'item_v2':\n",
    "        print(parts[-1].split(\"_\")[3])\n",
    "        return parts[-1].split(\"_\")[3]\n",
    "    elif len(parts) >2 and parts[0] == 'nidem':\n",
    "        return parts[-1].split(\"_\")[2]\n",
    "    elif len(parts) >2 and parts[0] == 'projects' or parts[0] == 'weathering-intensity':\n",
    "        return ' '\n",
    "    elif len(parts) >2 and parts[0] == 'multi-scale-topographic-position':\n",
    "        return ' '\n",
    "    else:\n",
    "        return '<none>'\n",
    "\n",
    "\n",
    "def merge_pre(folder, dicts):\n",
    "    today = datetime.date.today() \n",
    "    return {\n",
    "        'hits': max(int(d['hits']) for d in dicts),\n",
    "        'bytes/GB': round(sum(int(d['bytes']) for d in dicts)/1000000000,2),\n",
    "        #'cost': sum(float(d['cost']) for d in dicts),\n",
    "        'spatial_id': spatial_id(folder),\n",
    "        'product': product_name(folder),\n",
    "        #'folder': folder,\n",
    "        #date': str(datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "        'date': file_date + '-01',\n",
    "        'Lat' : latcord(folder, spatial_id(folder)),\n",
    "        'Lon' : loncord(folder, spatial_id(folder))\n",
    "    }\n",
    "\n",
    "def group(entry_list, key):\n",
    "    lookup = defaultdict(list)\n",
    "    \n",
    "    for d in entry_list:\n",
    "        lookup[d[key]].append(d)\n",
    "        \n",
    "    return lookup\n",
    "    \n",
    "\n",
    "def merge(dicts):\n",
    "    return {\n",
    "        'hits': sum(int(d['hits']) for d in dicts),\n",
    "        'bytes': sum(int(d['bytes']) for d in dicts),\n",
    "        #'cost': sum(float(d['cost']) for d in dicts),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2 = [merge_pre(key, value) for key, value in group(all_entries, 'folder').items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [d for d in stage2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('australian-mgrs-tiles.geojson') as fl:\n",
    "    input_gj = json.load(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albers_grid.geojson') as fl:\n",
    "    input_gj_2 = json.load(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2= input_gj_2['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = input_gj['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in feats2:\n",
    "    if 'label' in feat['properties']:\n",
    "        label = feat['properties']['label']\n",
    "        for dict_item in products:\n",
    "            if (dict_item['spatial_id']) == label:\n",
    "                polygon = Polygon(feat[\"geometry\"]['coordinates'][0]) \n",
    "                dict_item['Lat'] = round(polygon.centroid.y, 1)\n",
    "                dict_item['Lon'] = round(polygon.centroid.x, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in feats:\n",
    "    if 'MGRS' in feat['properties']:\n",
    "        mgrs = feat['properties']['MGRS']\n",
    "        count=0\n",
    "        for dict_item in products:\n",
    "            if (dict_item['spatial_id']) == mgrs:\n",
    "                polygon = Polygon(feat[\"geometry\"]['coordinates'][0])\n",
    "                dict_item['Lat'] = round(polygon.centroid.y, 1)\n",
    "                dict_item['Lon'] = round(polygon.centroid.x, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel2 = [d for d in stage2 if d['product'] == 'L2/sentinel-2-nrt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sentinel2[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newdata.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newdata.csv', 'a') as f:\n",
    "    dict_writer = csv.DictWriter(f, keys)\n",
    "    dict_writer.writerows(products)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
